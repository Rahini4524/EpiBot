{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f867b6c4-b99d-4e09-9ab6-8e8346de6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784cdaa0-062a-43f3-a20d-fb3446885ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_classes = 23\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0c4805-5be2-434d-9637-27071ee4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2db059e-740a-424f-bad9-a96862062d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:/rahini/balanced_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de61a73d-1d4d-4a04-b72e-b7014759b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784a0f64-724c-4b87-8fe7-51ac19d89cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class sample counts\n",
    "class_sample_counts = [sum(np.array(image_datasets['train'].targets) == i) for i in range(len(class_names))]\n",
    "class_weights = 1. / np.array(class_sample_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516cd43d-e8da-458e-a243-105568402bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[960, 960, 960, 960, 960, 960, 960, 960, 960, 960]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sample_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b5245a-6adf-420b-856b-3d191eb1340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00104167, 0.00104167, 0.00104167, 0.00104167, 0.00104167,\n",
       "       0.00104167, 0.00104167, 0.00104167, 0.00104167, 0.00104167])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bcee8b2-5585-47cf-b988-5393f7d896e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to each sample\n",
    "sample_weights = [class_weights[target] for target in image_datasets['train'].targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde0655f-b9b5-4325-97ee-4e3ce31e64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader with weighted sampler for training\n",
    "train_loader = DataLoader(image_datasets['train'], batch_size=batch_size, sampler=sampler,num_workers=4, pin_memory=True)\n",
    "validation_loader = DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=True,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ecd504f-65f0-4f96-85c9-2d023d4fc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of dataloaders\n",
    "dataloaders = {'train': train_loader, 'test': validation_loader}\n",
    "\n",
    "# Dataset sizes for each phase\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6838798-f827-413d-a8f4-d78f234ac481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust the final layer\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52009fb4-fb13-4b70-b8dd-21869990fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df598113-b8a5-47b9-b4b2-5aaf07248375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15c9aed-9eff-4c84-a50e-b3f423d8763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "train Loss: 1.5047 Acc: 0.4294\n",
      "test Loss: 1.3404 Acc: 0.4767\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss: 1.2693 Acc: 0.5064\n",
      "test Loss: 1.2342 Acc: 0.5042\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss: 1.1828 Acc: 0.5429\n",
      "test Loss: 1.2202 Acc: 0.5262\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss: 1.1002 Acc: 0.5784\n",
      "test Loss: 1.1325 Acc: 0.5604\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss: 1.0208 Acc: 0.6076\n",
      "test Loss: 1.1439 Acc: 0.5729\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss: 0.9742 Acc: 0.6320\n",
      "test Loss: 1.1140 Acc: 0.5971\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss: 0.9156 Acc: 0.6528\n",
      "test Loss: 1.0613 Acc: 0.6088\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss: 0.8564 Acc: 0.6795\n",
      "test Loss: 1.1412 Acc: 0.6000\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss: 0.7477 Acc: 0.7232\n",
      "test Loss: 1.3278 Acc: 0.5713\n",
      "Epoch 10/10\n",
      "----------\n",
      "train Loss: 0.6826 Acc: 0.7502\n",
      "test Loss: 1.1991 Acc: 0.6250\n",
      "Best Validation Accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, dataloaders, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9a84d7c-f4cc-455b-b054-4a1bb6b83f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '10XModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710f244-55d8-43e7-87bf-7a6819aba20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, model, class_names):\n",
    "    model.eval()\n",
    "    transform = data_transforms['test']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    # image.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    return class_names[preds.item()]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
